# Awesome 3D Generation [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)
> üéØ A curated list of papers on 3D generation with visual previews - see research at a glance.

> üåü Papers are organized by different 3D representations: Mesh, SDF (Signed Distance Function), Point Cloud, NeRF, and more.

> üìö We also include papers that, while not strictly about generation, demonstrate valuable techniques and insights for 3D generation research.

> üè† You can also check our [Project Homepage](https://awesome3dgen.com/).

üî•üî•üî• Also check out our awesome list about [Neural CAD](https://github.com/BunnySoCrazy/Awesome-Neural-CAD).


## Mesh

| Preview | Title | Publication | Links |
|:---:|:---|:---:|:---:|
| <img src="assets/img/QuadGPT.jpg" width="300"> | QuadGPT: Native Quadrilateral Mesh Generation with Autoregressive Models | arXiv 2025 | [Paper](https://arxiv.org/pdf/2509.21420) |
| <img src="assets/img/ARMesh.jpg" width="300"> | ARMesh: Autoregressive Mesh Generation via Next-Level-of-Detail Prediction | arXiv 2025 | [Paper](https://arxiv.org/pdf/2509.20824) <br> [Project](https://jblei.site/proj/armesh) |
| <img src="assets/img/MeshCoder.jpg" width="300"> | MeshCoder: LLM-Powered Structured Mesh Code Generation from Point Clouds | arXiv 2025 | [Paper](https://arxiv.org/pdf/2508.14879) <br> [Project](https://daibingquan.github.io/MeshCoder/) <br> [Code](https://github.com/InternRobotics/MeshCoder) |
| <img src="assets/img/VertexRegen.jpg" width="300"> | VertexRegen: Mesh Generation with Continuous Level of Detail | arXiv 2025 | [Paper](https://arxiv.org/pdf/2508.09062) <br> [Project](https://vertexregen.github.io/) |
| <img src="assets/img/FastMesh.jpg" width="300"> | FastMesh: Efficient Artistic Mesh Generation via Component Decoupling | arXiv 2025 | [Paper](https://arxiv.org/pdf/2508.19188) |
| <img src="assets/img/LLaMAMesh.jpg" width="300"> | LLaMA-Mesh: Unifying 3D Mesh Generation with Language Models | arXiv 2024 | [Paper](https://arxiv.org/pdf/2411.09595) <br> [Code](https://github.com/nv-tlabs/LLaMA-Mesh) <br> [Demo](https://huggingface.co/spaces/Zhengyi/LLaMA-Mesh) |
| <img src="assets/img/FreeMesh.jpg" width="300"> | FreeMesh: Boosting Mesh Generation with Coordinates Merging | ICML 2025 | [Paper](https://arxiv.org/pdf/2505.13573) |
| <img src="assets/img/MeshRFT.jpg" width="300"> | Mesh-RFT: Enhancing Mesh Generation via Fine-grained Reinforcement Fine-Tuning | arXiv 2025 | [Paper](https://arxiv.org/pdf/2505.16761) |
| <img src="assets/img/ScalingMesh.jpg" width="300"> | Scaling mesh generation via compressive tokenization | CVPR 2025 | [Paper](https://arxiv.org/pdf/2411.07025) <br> [Project](https://whaohan.github.io/bpt/) <br> [Code](https://github.com/tencent-hunyuan/bpt) |
| <img src="assets/img/iFlame.jpg" width="300"> | iFlame: Interleaving Full and Linear Attention for Efficient Mesh Generation | arXiv 2025 | [Paper](https://arxiv.org/pdf/2503.16653) <br> [Code](https://github.com/hanxiaowang00/iFlame) |
| <img src="assets/img/MeshSilksong.jpg" width="300"> | Mesh Silksong: Auto-Regressive Mesh Generation as Weaving Silk | arXiv 2025 | [Paper](https://arxiv.org/pdf/2507.02477) |
| <img src="assets/img/MeshPad.jpg" width="300"> | MeshPad: Interactive Sketch-Conditioned Artist-Designed Mesh Generation and Editing | arXiv 2025 | [Paper](https://arxiv.org/pdf/2503.01425) <br> [Project](https://derkleineli.github.io/meshpad/) |
| <img src="assets/img/DeepMesh.jpg" width="300"> | DeepMesh: Auto-Regressive Artist-mesh Creation with Reinforcement Learning | ICCV 2025 | [Paper](https://arxiv.org/pdf/2503.15265) <br> [Project](https://zhaorw02.github.io/DeepMesh/) <br> [Code](https://github.com/zhaorw02/DeepMesh) |
| <img src="assets/img/EdgeRunner.jpg" width="300"> | EdgeRunner: Auto-regressive Auto-encoder for Artistic Mesh Generation | ICLR 2025 | [Paper](https://arxiv.org/pdf/2409.18114) <br> [Code](https://github.com/NVlabs/EdgeRunner) |
| <img src="assets/img/MeshArt.jpg" width="300"> | MeshArt: Generating Articulated Meshes with Structure-guided Transformers | CVPR 2025 | [Paper](https://arxiv.org/pdf/2412.11596) <br> [Code](https://github.com/DaoyiG/MeshArt) |
| <img src="assets/img/TreeMeshGPT.jpg" width="300"> | TreeMeshGPT: Topology-Aware Mesh Generation with Tree-Structured Graph Priors | CVPR 2025 | [Paper](https://arxiv.org/pdf/2503.11629) |
| <img src="assets/img/Meshtron.jpg" width="300"> | Meshtron: High-Fidelity, Artist-Like 3D Mesh Generation at Scale | arXiv 2024 | [Paper](https://arxiv.org/pdf/2412.09548) <br> [Project](https://meshtron.github.io/) |
| <img src="assets/img/MeshAnythingV2.jpg" width="300"> | MeshAnything V2: Artist-Created Mesh Generation With Adjacent Mesh Tokenization | ICCV 2025 | [Paper](https://arxiv.org/pdf/2408.02555) <br> [Project](https://buaacyw.github.io/meshanything-v2/) <br> [Code](https://github.com/buaacyw/MeshAnything) |
| <img src="assets/img/MeshXL.jpg" width="300"> | MeshXL: Neural Coordinate Field for Generative 3D Foundation Models | NeurIPS 2024 | [Paper](https://arxiv.org/pdf/2405.20853) <br> [Code](https://github.com/OpenMeshLab/MeshXL) |
| <img src="assets/img/SpaceMesh.jpg" width="300"> | SpaceMesh: A Continuous Representation for Learning Manifold Surface Meshes | SIGGRAPH Asia 2024 | [Paper](https://arxiv.org/pdf/2409.20562) <br> [Project](https://research.nvidia.com/labs/toronto-ai/space-mesh/) |
| <img src="assets/img/PivotMesh.jpg" width="300"> | PivotMesh: Generic 3D Mesh Generation via Pivot Vertices Guidance | ICLR 2025 | [Paper](https://arxiv.org/pdf/2405.16890) <br> [Project](https://whaohan.github.io/pivotmesh/) <br> [Code](https://github.com/whaohan/pivotmesh) |
| <img src="assets/img/MeshAnything.jpg" width="300"> | MeshAnything: Artist-Created Mesh Generation with Autoregressive Transformers | ICLR 2025 | [Paper](https://arxiv.org/pdf/2406.10163) <br> [Project](https://buaacyw.github.io/mesh-anything/) <br> [Code](https://github.com/buaacyw/MeshAnything) |
| <img src="assets/img/MeshGPT.jpg" width="300"> | MeshGPT: Generating Triangle Meshes with Decoder-Only Transformers | CVPR 2024 | [Paper](https://arxiv.org/pdf/2311.15475) <br> [Code](https://github.com/lucidrains/meshgpt-pytorch) |
| <img src="assets/img/PolyDiff.jpg" width="300"> | PolyDiff: Generating 3D Polygonal Meshes with Diffusion Models | arXiv 2023 | [Paper](https://arxiv.org/pdf/2312.11417) |
| <img src="assets/img/PolyGen.jpg" width="300"> | PolyGen: An Autoregressive Generative Model of 3D Meshes | ICML 2020 | [Paper](https://arxiv.org/pdf/2002.10880) <br> [Code](https://github.com/google-deepmind/deepmind-research/tree/master/polygen) |


## Implicit Shape Representations (SDF and Occupancy Fields, etc.)

| Preview | Title | Publication | Links |
|:---:|:---|:---:|:---:|
| <img src="assets/img/TripoSF.jpg" width="300"> | SparseFlex: High-Resolution and Arbitrary-Topology 3D Shape Modeling (TripoSF) | arXiv 2025 | [Paper](https://arxiv.org/pdf/2503.21732) <br> [Code](https://github.com/VAST-AI-Research/TripoSF) |
| <img src="assets/img/Ultra3D.jpg" width="300"> | Ultra3D: Efficient and High-Fidelity 3D Generation with Part Attention | arXiv 2025 | [Paper](https://arxiv.org/pdf/2507.17745.pdf) |
| <img src="assets/img/Sparc3D.jpg" width="300"> | Sparc3D: Sparse Representation and Construction for High-Resolution 3D Shapes Modeling | arXiv 2025 | [Paper](https://arxiv.org/pdf/2505.14521) |
| <img src="assets/img/HierOctFusion.jpg" width="300"> | HierOctFusion: Multi-scale Octree-based 3D Shape Generation via Part-Whole-Hierarchy Message Passing | arXiv 2024 | [Paper](https://arxiv.org/pdf/2508.11106) |
| <img src="assets/img/TRELLIS.jpg" width="300"> | TRELLIS: Structured 3D Latents for Scalable and Versatile 3D Generation | CVPR 2025 | [Paper](https://arxiv.org/pdf/2412.01506) <br> [Code](https://github.com/microsoft/TRELLIS) |
| <img src="assets/img/OctFusion.jpg" width="300"> | OctFusion: Octree-based Diffusion Models for 3D Shape Generation | SGP 2025 | [Paper](https://arxiv.org/pdf/2408.14732) <br> [Code](https://github.com/octree-nn/octfusion) |
| <img src="assets/img/LaGeM.jpg" width="300"> | LaGeM: A Large Geometry Model for 3D Representation Learning and Diffusion | ICLR 2025 | [Paper](https://arxiv.org/abs/2410.01295) <br> [Code](https://github.com/1zb/LaGeM) <br> [Project](https://1zb.github.io/LaGeM/) |
| <img src="assets/img/XCube.jpg" width="300"> | XCube: Large-Scale 3D Generative Modeling using Sparse Voxel Hierarchies | CVPR 2024 | [Paper](https://arxiv.org/pdf/2312.03806) <br> [Code](https://github.com/nv-tlabs/XCube) |
| <img src="assets/img/SplatSDF.jpg" width="300"> | SplatSDF: Boosting Neural Implicit SDF via Gaussian Splatting Fusion | arXiv 2024 | [Paper](https://arxiv.org/pdf/2411.15468) |
| <img src="assets/img/MeshFormer.jpg" width="300"> | MeshFormer: High-Quality Mesh Generation with 3D-Guided Reconstruction Model | arXiv 2024 | [Paper](https://arxiv.org/pdf/2408.10198) |
| <img src="assets/img/Mosaic-SDF.jpg" width="300"> | Mosaic-SDF for 3D Generative Models | arXiv 2024 | [Paper](https://arxiv.org/pdf/2312.09222) |
| <img src="assets/img/CraftsMan.jpg" width="300"> | CraftsMan: High-fidelity Mesh Generation with 3D Native Generation and Interactive Geometry Refiner | arXiv 2024 | [Paper](https://arxiv.org/pdf/2405.14979) <br> [Code](https://github.com/wyysf-98/CraftsMan3D) |
| <img src="assets/img/GSDF.jpg" width="300"> | GSDF: 3DGS Meets SDF for Improved Neural Rendering and Reconstruction | NeurIPS 2024 | [Paper](https://arxiv.org/pdf/2403.16964) |
| <img src="assets/img/GEM3D.jpg" width="300"> | GEM3D: GEnerative Medial Abstractions for 3D Shape Synthesis | SIGGRAPH 2024 | [Paper](https://arxiv.org/abs/2402.16994) <br> [Code](https://github.com/lodurality/GEM3D_paper_code) <br> [Project](https://lodurality.github.io/GEM3D/) |
| <img src="assets/img/SurroundSDF.jpg" width="300"> | SurroundSDF: Implicit 3D Scene Understanding Based on Signed Distance Field | CVPR 2024 | [Paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Liu_SurroundSDF_Implicit_3D_Scene_Understanding_Based_on_Signed_Distance_Field_CVPR_2024_paper.pdf) |
| <img src="assets/img/HSDF.jpg" width="300"> | HSDF: Hybrid Sign and Distance Field for Neural Representation of Surfaces With Arbitrary Topologies | IEEE 2024 | [Paper](https://ieeexplore.ieee.org/document/10636762/) |
| <img src="assets/img/3DShape2VecSet.jpg" width="300"> | 3DShape2VecSet: A 3D Shape Representation for Neural Fields and Generative Diffusion Models | ACM TOG 2023 | [Paper](https://arxiv.org/pdf/2301.11445) <br> [Code](https://github.com/1zb/3DShape2VecSet) |
| <img src="assets/img/LocallyAttentionalSDF.jpg" width="300"> | Locally Attentional SDF Diffusion for Controllable 3D Shape Generation | ACM TOG 2023 | [Paper](https://arxiv.org/pdf/2305.04461) |
| <img src="assets/img/DiffusionSDF.jpg" width="300"> | Diffusion-SDF: Conditional Generative Modeling of Signed Distance Functions | ICCV 2023 | [Paper](https://light.princeton.edu/publication/diffusion-sdf/) <br> [Project](https://light.princeton.edu/publication/diffusion-sdf/) |
| <img src="assets/img/CSG-Neural-SDF.jpg" width="300"> | Constructive Solid Geometry on Neural Signed Distance Fields | ACM SIGGRAPH Asia 2023 | [Paper](https://dl.acm.org/doi/fullHtml/10.1145/3610548.3618170) <br> [Project](https://zoemarschner.com/research/csg_on_neural_sdfs.html) |
| <img src="assets/img/SDFusion.jpg" width="300"> | SDFusion: Multimodal 3D Shape Completion, Reconstruction, and Generation | CVPR 2023 | [Paper](https://yccyenchicheng.github.io/SDFusion/) <br> [Code](https://github.com/yccyenchicheng/SDFusion) |
| <img src="assets/img/SDF-Diffusion.jpg" width="300"> | SDF-Diffusion: Text-to-Shape via Voxelized Diffusion | CVPR 2023 | [Paper](https://arxiv.org/pdf/2212.03293) |
| <img src="assets/img/MeshDiffusion.jpg" width="300"> | MeshDiffusion: Score-based Generative 3D Mesh Modeling | ICLR 2023 | [Paper](https://arxiv.org/pdf/2303.08133) <br> [Code](https://github.com/lzzcd001/MeshDiffusion) |
| <img src="assets/img/SDF-StyleGAN.jpg" width="300"> | SDF-StyleGAN: Implicit SDF-Based StyleGAN for 3D Shape Generation | SGP 2022 | [Paper](https://arxiv.org/pdf/2206.12055) <br> [Code](https://github.com/Zhengxinyang/SDF-StyleGAN) |
| <img src="assets/img/neural_wavelet.jpg" width="300"> | Neural Wavelet-domain Diffusion for 3D Shape Generation, Inversion, and Manipulation | SIGGRAPH Asia 2022 <br> ACM TOG | [Paper](https://arxiv.org/abs/2302.00190) <br> [Code](https://github.com/edward1997104/Wavelet-Generation) |
| <img src="assets/img/AutoSDF.jpg" width="300"> | AutoSDF: Shape Priors for 3D Completion, Reconstruction and Generation | CVPR 2022 | [Paper](https://arxiv.org/pdf/2203.09516) |
| <img src="assets/img/3DILG.jpg" width="300"> | 3DILG: Irregular Latent Grids for 3D Generative Modeling | NeurIPS 2022 | [Paper](https://arxiv.org/abs/2205.13914) <br> [Code](https://github.com/1zb/3DILG) <br> [Project](https://1zb.github.io/3DILG/) |
| <img src="assets/img/NeuS.jpg" width="300"> | NeuS: Learning Neural Implicit Surfaces by Volume Rendering for Multi-view Reconstruction | NeurIPS 2021 | [Paper](https://arxiv.org/pdf/2106.10689) <br> [Code](https://github.com/Totoro97/NeuS) |
| <img src="assets/img/SIREN.jpg" width="300"> | SIREN: Implicit Neural Representations with Periodic Activation Functions | NeurIPS 2020 | [Paper](https://arxiv.org/pdf/2006.09661) <br> [Code](https://github.com/vsitzmann/siren) |
| <img src="assets/img/DeepSDF.jpg" width="300"> | DeepSDF: Learning Continuous Signed Distance Functions for Shape Representation | CVPR 2019 | [Paper](https://arxiv.org/pdf/1901.05103) <br> [Code](https://github.com/facebookresearch/DeepSDF) |
| <img src="assets/img/NDF.jpg" width="300"> | Neural Unsigned Distance Fields for Implicit Function Learning | NeurIPS 2020 |  [Paper](https://arxiv.org/pdf/2010.13938) |
| <img src="assets/img/ConvOccNets.jpg" width="300"> | Convolutional Occupancy Networks | ECCV 2020 | [Paper](https://arxiv.org/pdf/2003.04618) <br> [Code](https://github.com/autonomousvision/convolutional_occupancy_networks) |
| <img src="assets/img/IM-Net.jpg" width="300"> | IM-Net: Learning Implicit Fields for Generative Shape Modeling | CVPR 2019 | [Paper](https://arxiv.org/abs/1812.02822) <br> [Code](https://github.com/czq142857/implicit-decoder) |


## Point Cloud

| Preview | Title | Publication | Links |
|:---:|:---|:---:|:---:|
| <img src="assets/img/TopoDiT-3D.jpg" width="300"> | TopoDiT-3D: Topology-Aware Diffusion Transformer with Bottleneck Structure for 3D Point Cloud Generation | arXiv 2025 | [Paper](https://arxiv.org/pdf/2505.09140.pdf) |
| <img src="assets/img/PointARU.jpg" width="300"> | 3D Point Cloud Generation via Autoregressive Up-sampling | arXiv 2025 | [Paper](https://arxiv.org/pdf/2503.08594.pdf) |
| <img src="assets/img/EAGLE.jpg" width="300"> | EAGLE: Contextual Point Cloud Generation via Adaptive Continuous Normalizing Flow with Self-Attention | arXiv 2025 | [Paper](https://arxiv.org/pdf/2503.13479.pdf) |
| <img src="assets/img/NotSoOptimalTransport.jpg" width="300"> | Not-So-Optimal Transport Flows for 3D Point Cloud Generation | arXiv 2025 | [Paper](https://arxiv.org/pdf/2502.12456.pdf) |
| <img src="assets/img/RGB2Point.jpg" width="300"> | RGB2Point: 3D Point Cloud Generation from Single RGB Images | arXiv 2024 | [Paper](https://arxiv.org/pdf/2407.14979.pdf) |
| <img src="assets/img/FastDiT-3D.jpg" width="300"> | Fast Training of Diffusion Transformer with Extreme Masking for 3D Point Clouds Generation | ECCV 2024 | [Paper](https://arxiv.org/pdf/2312.07231.pdf) |
| <img src="assets/img/ContextAware-PCGen.jpg" width="300"> | Context-Aware Indoor Point Cloud Object Generation through User Instructions | ACM Multimedia 2024 | [Paper](https://arxiv.org/pdf/2311.16501.pdf) |
| <img src="assets/img/GenerativeCellularAutomata.jpg" width="300"> | Learning to Generate 3D Shapes with Generative Cellular Automata | ICLR 2021 | [Paper](https://arxiv.org/pdf/2103.04130) |
| <img src="assets/img/PointVoxelDiffusion.jpg" width="300"> | 3D Shape Generation and Completion through Point-Voxel Diffusion | ICCV 2021 | [Paper](https://arxiv.org/pdf/2104.03670.pdf) <br> [Code](https://github.com/alexzhou907/PVD) |


## NeRF

| Preview | Title | Publication | Links |
|:---:|:---|:---:|:---:|
| <img src="assets/img/One-2-3-45++.jpg" width="300"> | One-2-3-45++: Fast Single Image to 3D Objects with Consistent Multi-View Generation and 3D Diffusion | CVPR 2024 | [Paper](https://arxiv.org/pdf/2311.07885.pdf) <br> [Project](https://sudo-ai-3d.github.io/One2345plus_page/) |
| <img src="assets/img/ProlificDreamer.jpg" width="300"> | ProlificDreamer: High-Fidelity and Diverse Text-to-3D Generation with Variational Score Distillation | NeurIPS 2023 | [Paper](https://arxiv.org/pdf/2305.16213.pdf) <br> [Code](https://github.com/thu-ml/prolificdreamer) <br> [Project](https://ml.cs.tsinghua.edu.cn/prolificdreamer/) |
| <img src="assets/img/One-2-3-45.jpg" width="300"> | One-2-3-45: Any Single Image to 3D Mesh in 45 Seconds without Per-Shape Optimization | NeurIPS 2023 | [Paper](https://arxiv.org/pdf/2306.16928) <br> [Code](https://github.com/One-2-3-45/One-2-3-45) <br> [Project](https://one-2-3-45.github.io/) |
| <img src="assets/img/Zero123.jpg" width="300"> | Zero-1-to-3: Zero-shot One Image to 3D Object | ICCV 2023 | [Paper](https://arxiv.org/pdf/2303.11328.pdf) <br> [Code](https://github.com/cvlab-columbia/zero123) <br> [Project](https://zero123.cs.columbia.edu/) |
| <img src="assets/img/Magic3D.jpg" width="300"> | Magic3D: High-Resolution Text-to-3D Content Creation | CVPR 2023 | [Paper](https://arxiv.org/pdf/2211.10440.pdf) <br> [Project](https://research.nvidia.com/labs/dir/magic3d/) |
| <img src="assets/img/DreamFusion.jpg" width="300"> | DreamFusion: Text-to-3D using 2D Diffusion | arXiv 2022 | [Paper](https://arxiv.org/pdf/2209.14988.pdf) <br> [Project](https://dreamfusion3d.github.io/) |
| <img src="assets/img/EG3D.jpg" width="300"> | Efficient Geometry-aware 3D Generative Adversarial Networks | CVPR 2022 | [Paper](https://arxiv.org/pdf/2112.07945.pdf) <br> [Code](https://github.com/NVlabs/eg3d) <br> [Project](https://nvlabs.github.io/eg3d/) |

## 3D Gaussian Splatting

| Preview | Title | Publication | Links |
|:---:|:---|:---:|:---:|
| <img src="assets/img/VRSplat.jpg" width="300"> | VRSplat: Fast and Robust Gaussian Splatting for Virtual Reality | arXiv 2025 | [Paper](https://arxiv.org/pdf/2505.10144) |
| <img src="assets/img/GaussianSDF.jpg" width="300"> | Gaussian Splatting with Discretized SDF for Relightable Assets | arXiv 2025 | [Paper](https://arxiv.org/pdf/2507.15629) |
| <img src="assets/img/GaussianCompression.jpg" width="300"> | Enhancing 3D Gaussian Splatting Compression via Spatial Condition-based Prediction | arXiv 2025 | [Paper](https://arxiv.org/pdf/2503.23337) |
| <img src="assets/img/GSurvey2024.jpg" width="300"> | 3D Gaussian Splatting as a New Era: A Survey | IEEE TVCG 2024 | [Paper](https://ieeexplore.ieee.org/document/10521791/) |
| <img src="assets/img/WildGaussians.jpg" width="300"> | WildGaussians: 3D Gaussian Splatting In the Wild | NeurIPS 2024 | [Paper](https://neurips.cc/virtual/2024/poster/95434) |
| <img src="assets/img/SpecGaussian.jpg" width="300"> | Spec-Gaussian: Anisotropic View-Dependent Appearance for 3D Gaussian Splatting | NeurIPS 2024 | [Paper](https://nips.cc/virtual/2024/poster/93509) |
| <img src="assets/img/ODGS.jpg" width="300"> | ODGS: 3D Scene Reconstruction from Omnidirectional Images with 3D Gaussian Splattings | NeurIPS 2024 | [Paper](https://arxiv.org/pdf/2410.20686) <br> [Code](https://github.com/esw0116/ODGS) |
| <img src="assets/img/DOGS.jpg" width="300"> | DOGS: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction | NeurIPS 2024 | [Paper](https://arxiv.org/pdf/2405.13943) <br> [Code](https://github.com/AIBluefisher/DOGS) |
| <img src="assets/img/FreeSplat.jpg" width="300"> | FreeSplat: Generalizable 3D Gaussian Splatting for Free-View Synthesis | NeurIPS 2024 | [Paper](https://arxiv.org/pdf/2405.17958) <br> [Code](https://github.com/wangys16/FreeSplat) |
| <img src="assets/img/MCMCGS.jpg" width="300"> | 3D Gaussian Splatting as Markov Chain Monte Carlo | NeurIPS 2024 (Spotlight) | [Paper](https://arxiv.org/pdf/2404.09591) |
| <img src="assets/img/3iGS.jpg" width="300"> | 3iGS: Factorised Tensorial Illumination for 3D Gaussian Splatting | ECCV 2024 | [Paper](https://eccv.ecva.net/virtual/2024/poster/2035) |
| <img src="assets/img/HeadStudio.jpg" width="300"> | HeadStudio: Text to Animatable Head Avatars with 3D Gaussian Splatting | ECCV 2024 | [Paper](https://link.springer.com/chapter/10.1007/978-3-031-73411-3_9) |
| <img src="assets/img/GaussianGrouping.jpg" width="300"> | Gaussian Grouping: Segment and Edit Anything in 3D Scenes | ECCV 2024 | [Paper](https://arxiv.org/pdf/2312.00732) <br> [Code](https://github.com/lkeab/gaussian-grouping) |
| <img src="assets/img/2DGS.jpg" width="300"> | 2D Gaussian Splatting for Geometrically Accurate Radiance Fields | SIGGRAPH 2024 | [Paper](https://arxiv.org/pdf/2403.17888.pdf) <br> [Code](https://github.com/hbb1/2d-gaussian-splatting) |
| <img src="assets/img/RecentAdvances.jpg" width="300"> | Recent Advances in 3D Gaussian Splatting | arXiv 2024 | [Paper](https://arxiv.org/pdf/2403.11134) |
| <img src="assets/img/COLMAPFREE.jpg" width="300"> | COLMAP-Free 3D Gaussian Splatting | CVPR 2024 | [Paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Fu_COLMAP-Free_3D_Gaussian_Splatting_CVPR_2024_paper.pdf) |
| <img src="assets/img/GaussianSLAM.jpg" width="300"> | Gaussian Splatting SLAM | CVPR 2024 (Best Demo) | [Paper](https://openaccess.thecvf.com/content/CVPR2024/html/Matsuki_Gaussian_Splatting_SLAM_CVPR_2024_paper.html) |
| <img src="assets/img/MipSplatting.jpg" width="300"> | Mip-Splatting: Alias-free 3D Gaussian Splatting | CVPR 2024 (Best Student Paper) | [Paper](https://arxiv.org/pdf/2311.16493) <br> [Code](https://niujinshuchong.github.io/mip-splatting/) |
| <img src="assets/img/DreamGaussian.jpg" width="300"> | DreamGaussian: Generative Gaussian Splatting for Efficient 3D Content Creation | ICLR 2024 (Oral) | [Paper](https://arxiv.org/pdf/2309.16653.pdf) <br> [Code](https://github.com/dreamgaussian/dreamgaussian) |
| <img src="assets/img/3DGS.jpg" width="300"> | 3D Gaussian Splatting for Real-Time Radiance Field Rendering | SIGGRAPH 2023 | [Paper](https://arxiv.org/pdf/2308.04079.pdf) <br> [Code](https://github.com/graphdeco-inria/gaussian-splatting) |
| <img src="assets/img/ASurvey.jpg" width="300"> | A Survey on 3D Gaussian Splatting | arXiv 2024 | [Paper](https://arxiv.org/pdf/2401.03890) |
| <img src="assets/img/SuGaR.jpg" width="300"> | SuGaR: Surface-Aligned Gaussian Splatting for Efficient 3D Mesh Reconstruction and High-Quality Mesh Rendering | CVPR 2024 | [Paper](https://github.com/Anttwo/SuGaR) <br> [Code](https://github.com/Anttwo/SuGaR) |


## CAD

| Preview | Title | Publication | Links |
|:---:|:---|:---:|:---:|
| <img src="assets/img/GeoCAD.jpg" width="300"> | GeoCAD: Local Geometry-Controllable CAD Generation | arXiv 2025 | [Paper](https://arxiv.org/pdf/2506.10337) |
| <img src="assets/img/CAD-Coder.jpg" width="300"> | CAD-Coder: Text-to-CAD Generation with Chain-of-Thought and Geometric Reward | arXiv 2025 | [Paper](https://arxiv.org/pdf/2505.19713) |
| <img src="assets/img/Stitch-A-Shape.jpg" width="300"> | Stitch-A-Shape: Bottom-up Learning for B-Rep Generation | SIGGRAPH 2025 | [Paper](https://dl.acm.org/doi/pdf/10.1145/3721238.3730661) |
| <img src="assets/img/BrepDiff.jpg" width="300"> | BrepDiff: Single-stage B-rep Diffusion Model | SIGGRAPH 2025 | [Paper](https://dl.acm.org/doi/pdf/10.1145/3721238.3730698) <br> [Project](https://brepdiff.github.io/) |
| <img src="assets/img/HoLa.jpg" width="300"> | HoLa: B-Rep Generation using a Holistic Latent Representation | SIGGRAPH 2025 | [Paper](https://arxiv.org/abs/2504.14257) <br> [Project](https://vcc.tech/research/2025/HolaBRep) |
| <img src="assets/img/CLR-Wire.jpg" width="300"> | CLR-Wire: Towards Continuous Latent Representations for 3D Curve Wireframe Generation | SIGGRAPH 2025 | [Paper](https://arxiv.org/pdf/2504.19174) <br> [Code](https://github.com/qixuema/CLR-Wire) |
| <img src="assets/img/DTGBrepGen.jpg" width="300"> | DTGBrepGen: A Novel B-rep Generative Model through Decoupling Topology and Geometry | CVPR 2025 | [Paper](https://arxiv.org/pdf/2503.13110) <br> [Code](https://github.com/jinli99/DTGBrepGen) <br> [Project](https://jinli99.github.io/DTGBrepGen/) |
| <img src="assets/img/CADCrafter.png" width="300"> | CADCrafter: Generating Computer-Aided Design Models from Unconstrained Images | CVPR 2025 | [Paper](https://arxiv.org/pdf/2504.04753)|
| <img src="assets/img/CADDreamer.jpg" width="300"> | CADDreamer: CAD object Generation from Single-view Images | CVPR 2025 | [Paper](https://arxiv.org/pdf/2502.20732) <br> [Project](https://lidan233.github.io/caddreamer/) |
| <img src="assets/img/CAD-GPT.jpg" width="400"> | CAD-GPT: Synthesising CAD Construction Sequence with Spatial Reasoning-Enhanced Multimodal LLMs | arXiv 2025 | [Paper](https://arxiv.org/pdf/2412.19663) <br> [Project](https://openiwin.github.io/CAD-GPT/) |
| <img src="assets/img/Text-to-CAD.jpg" width="400"> | Text-to-CAD Generation Through Infusing Visual Feedback in Large Language Models | arXiv 2025 | [Paper](https://arxiv.org/pdf/2501.19054) |
| <img src="assets/img/RECAD.jpg" width="400"> | Revisiting CAD Model Generation by Learning Raster Sketch | AAAI 2025 | [Paper](https://www.arxiv.org/pdf/2503.00928)   <br> [Dataset](https://github.com/BunnySoCrazy/RECAD)|
| <img src="assets/img/FLEXCAD.jpg" width="400"> | FlexCAD: Unified and Versatile Controllable CAD Generation with Fine-tuned Large Language Models | ICLR 2025 | [Paper](https://arxiv.org/pdf/2411.05823)  <br> [Code](https://github.com/microsoft/FlexCAD) |
| <img src="assets/img/CAD_Code_Generation.jpg" width="400"> | Generating CAD Code with Vision-Language Models for 3D Designs | ICLR 2025 | [Paper](https://arxiv.org/pdf/2410.05340)  <br> [Code](https://github.com/Kamel773/CAD_Code_Generation) |
| <img src="assets/img/DontMeshwithMe.jpg" width="400"> | Don‚Äôt Mesh with Me: Generating Constructive Solid Geometry Instead of Meshes by Fine-Tuning a Code-Generation LLM | arXiv 2024 | [Paper](https://arxiv.org/pdf/2411.15279) |
| <img src="assets/img/CAD-MLLM.jpg" width="400"> | CAD-MLLM: Unifying Multimodality-Conditioned CAD Generation With MLLM | arXiv 2024 | [Paper](https://arxiv.org/pdf/2411.04954) <br> [Project](https://cad-mllm.github.io/) |
| <img src="assets/img/text2CAD.jpg" width="400"> | Text2CAD: Text to 3D CAD Generation via Technical Drawings | NeurIPS 2024 | [Paper](https://arxiv.org/pdf/2411.06206) <br> [Code](https://github.com/SadilKhan/Text2CAD) <br> [Project](https://sadilkhan.github.io/text2cad-project/) |
| <img src="assets/img/CadVLM.jpg" width="400"> | CadVLM: Bridging Language and Vision in the Generation of Parametric CAD Sketches | ECCV 2024 | [Paper](https://arxiv.org/pdf/2409.17457)|
| <img src="assets/img/BrepGen.jpg" width="400"> | BrepGen: A B-rep Generative Diffusion Model with Structured Latent Geometry | SIGGRAPH 2024 | [Paper](https://arxiv.org/pdf/2401.15563) <br> [Code](https://github.com/samxuxiang/BrepGen) |
| <img src="assets/img/LEGO_Micro_Buildings.jpg" width="400"> | Learn to Create Simple LEGO Micro Buildings | SIGGRAPH Asia 2024 | [Paper](https://dlnext.acm.org/doi/pdf/10.1145/3687755) <br> [Code](https://github.com/Occulte/LEGO_Buildings_Generation) |
| <img src="assets/img/Generating_3D_House_Wireframes.jpg" width="400"> | Generating 3D House Wireframes with Semantics | ECCV 2024 | [Paper](https://arxiv.org/pdf/2407.12267) <br> [Project](https://vcc.tech/research/2024/3DWire) |
| <img src="assets/img/SolidGen.jpg" width="400"> | SolidGen: An Autoregressive Model for Direct B-rep Synthesis | ICLR 2024 | [Paper](https://openreview.net/pdf?id=ZR2CDgADRo) |
| <img src="assets/img/Brep2Seq.jpg" width="400"> | Brep2Seq: A Dataset and Hierarchical Deep Learning Network for Reconstruction and Generation of Computer-Aided Design Models | JCDE 2024 | [Paper](https://academic.oup.com/jcde/article/11/1/110/7582276)  <br> [Code](https://github.com/zhangshuming0668/Brep2Seq) |
| <img src="assets/img/vq_diff.jpg" width="400"> | VQ-CAD: Computer-Aided Design model generation with vector quantized diffusion | CAGD 2024 | [Paper](https://www.sciencedirect.com/science/article/pii/S016783962400061X) |
| <img src="assets/img/PartNeRF.jpg" width="400"> | PartNeRF: Generating Part-Aware Editable 3D Shapes without 3D Supervision | CVPR 2023 | [Paper](https://arxiv.org/pdf/2303.09554) <br> [Code](https://github.com/ktertikas/part_nerf)  <br> [Project](https://ktertikas.github.io/part_nerf) |
| <img src="assets/img/HNCCAD.jpg" width="400"> | Hierarchical Neural Coding for Controllable CAD Model Generation | ICML 2023 | [Paper](https://arxiv.org/pdf/2307.00149) <br> [Code](https://github.com/samxuxiang/hnc-cad) <br> [Project](https://hnc-cad.github.io/) |
| <img src="assets/img/SkexGen.jpg" width="400"> | SkexGen: Autoregressive Generation of CAD Construction Sequences with Disentangled Codebooks | ICML 2022 | [Paper](https://arxiv.org/pdf/2207.04632) <br> [Code](https://github.com/samxuxiang/SkexGen) <br> [Project](https://samxuxiang.github.io/skexgen) |
| <img src="assets/img/Free2CAD.jpg" width="400"> | Free2CAD: Parsing Freehand Drawings into CAD Commands | SIGGRAPH 2022 | <br> [Code](https://github.com/Enigma-li/Free2CAD) <br> [Project](https://geometry.cs.ucl.ac.uk/projects/2022/free2cad/) |
| <img src="assets/img/DeepCAD.jpg" width="400"> | DeepCAD: A Deep Generative Network for Computer-Aided Design Models | ICCV 2021| [Paper](https://arxiv.org/pdf/2105.09492) <br> [Code](https://github.com/ChrisWu1997/DeepCAD) <br> [Project](http://www.cs.columbia.edu/cg/deepcad/) |
| <img src="assets/img/Roof-GAN.jpg" width="400"> | Roof-GAN: Learning to Generate Roof Geometry and Relations for Residential Houses | CVPR 2021 | [Paper](https://arxiv.org/pdf/2012.09340)  <br> [Code](https://github.com/yi-ming-qian/roofgan) |
| <img src="assets/img/CADasLanguage.jpg" width="400"> | Computer-aided design as language | NeurIPS 2021 | [Paper](https://arxiv.org/pdf/2105.02769)|
| <img src="assets/img/SDM-NET.jpg" width="400"> | SDM-NET: Deep Generative Network for Structured Deformable Mesh | TOG 2019 | [Paper](https://dl.acm.org/doi/pdf/10.1145/3355089.3356488) <br> [Code](https://github.com/gaolinorange/SDMNET_stamp) |
| <img src="assets/img/StructureNet.jpg" width="400"> | StructureNet: Hierarchical Graph Networks for 3D Shape Generation | Siggraph Asia 2019 | [Paper](https://arxiv.org/pdf/1908.00575) <br> [Code](https://github.com/daerduoCarey/structurenet) <br> [Project](https://cs.stanford.edu/~kaichun/structurenet/) |
| <img src="assets/img/AtlasNet.jpg" width="400"> | AtlasNet: A Papier-M√¢ch√© Approach to Learning 3D Surface Generation | CVPR 2018 | [Paper](https://arxiv.org/pdf/1802.05384) <br> [Code](https://github.com/ThibaultGROUEIX/AtlasNet) <br> [Project](https://imagine.enpc.fr/~groueixt/atlasnet/) |


## Voxel

| Preview | Title | Publication | Links |
|:---:|:---|:---:|:---:|
| <img src="assets/img/VoxMol.jpg" width="300"> | 3D molecule generation by denoising voxel grids | NeurIPS 2023 | [Paper](https://arxiv.org/pdf/2306.07473.pdf) |
| <img src="assets/img/AutoSDF.jpg" width="300"> | AutoSDF: Shape Priors for 3D Completion, Reconstruction and Generation | CVPR 2022 | [Paper](https://arxiv.org/pdf/2203.09516.pdf) <br> [Code](https://github.com/yccyenchicheng/AutoSDF) <br> [Project](https://yccyenchicheng.github.io/AutoSDF/) |
| <img src="assets/img/OctreeTransformer.jpg" width="300"> | Octree Transformer: Autoregressive 3D Shape Generation on Hierarchically Structured Sequences | arXiv 2021 | [Paper](https://arxiv.org/pdf/2111.12480.pdf) |
| <img src="assets/img/GenerativeVoxelNet.jpg" width="300"> | Generative VoxelNet: Learning Energy-Based Models for 3D Shape Synthesis and Analysis | TPAMI 2020 | [Paper](http://www.stat.ucla.edu/~jxie/3DDescriptorNet/3DDescriptorNet_file/doc/3DDescriptorNet.pdf) <br> [Code](https://github.com/jianwen-xie/3DDescriptorNet) <br> [Project](http://www.stat.ucla.edu/~jxie/3DDescriptorNet/3DDescriptorNet.html) |
| <img src="assets/img/PartAssembly.jpg" width="300"> | Learning Part Generation and Assembly for Structure-Aware Shape Synthesis | AAAI 2020 | [Paper](https://arxiv.org/pdf/1906.06693.pdf) |
| <img src="assets/img/PQNET.jpg" width="300"> | PQ-NET: A Generative Part Seq2Seq Network for 3D Shapes | CVPR 2020 | [Paper](https://arxiv.org/pdf/1911.10949.pdf) <br> [Code](https://github.com/ChrisWu1997/PQ-NET) |
| <img src="assets/img/GeneralizedAutoencoder.jpg" width="300"> | Generalized Autoencoder for Volumetric Shape Generation | CVPRW 2020 | [Paper](https://openaccess.thecvf.com/content_CVPRW_2020/papers/w17/Guan_Generalized_Autoencoder_for_Volumetric_Shape_Generation_CVPRW_2020_paper.pdf) <br> [Code](https://github.com/IsaacGuan/3D-GAE) |
| <img src="assets/img/SAGNet.jpg" width="300"> | SAGNet: Structure-aware Generative Network for 3D-Shape Modeling | SIGGRAPH 2019 | [Paper](https://dilincv.github.io/papers/SAGNet_sig2019.pdf) <br> [Code](https://github.com/zhijieW94/SAGNet) <br> [Project](https://vcc.tech/research/2019/SAGnet/) |
| <img src="assets/img/GenerativeDiscriminativeVoxel.jpg" width="300"> | Generative and Discriminative Voxel Modeling with Convolutional Neural Networks | arXiv 2016 | [Paper](https://arxiv.org/pdf/1608.04236.pdf) <br> [Code](https://github.com/ajbrock/Generative-and-Discriminative-Voxel-Modeling) |
| <img src="assets/img/3DGAN.jpg" width="300"> | Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling | NeurIPS 2016 | [Paper](https://arxiv.org/pdf/1610.07584.pdf) <br> [Code](https://github.com/zck119/3dgan-release) <br> [Project](http://3dgan.csail.mit.edu/) |


## Part-based 3D

| Preview | Title | Publication | Links |
|:---:|:---|:---:|:---:|
| <img src="assets/img/PartNeXt.jpg" width="300"> | PartNeXt: A Next-Generation Dataset for Fine-Grained and Hierarchical 3D Part Understanding | arXiv 2025 | [Paper](https://arxiv.org/pdf/2510.20155) |
| <img src="assets/img/FullPart.jpg" width="300"> | FullPart: Generating each 3D Part at Full Resolution | arXiv 2025 | [Paper](https://arxiv.org/pdf/2510.26140) |
| <img src="assets/img/BANG.jpg" width="300"> | BANG: Dividing 3D Assets via Generative Exploded Dynamics | arXiv 2025 | [Paper](https://arxiv.org/pdf/2507.21493) |
| <img src="assets/img/Assembler.jpg" width="300"> | Assembler: Scalable 3D Part Assembly via Anchor Point Diffusion | arXiv 2025 | [Paper](https://arxiv.org/pdf/2506.17074) |
| <img src="assets/img/DualVolumePacking.jpg" width="300"> | Efficient Part-level 3D Object Generation via Dual Volume Packing | arXiv 2025 | [Paper](https://arxiv.org/pdf/2506.09980) |
| <img src="assets/img/MeshArt.jpg" width="300"> | MeshArt: Generating Articulated Meshes with Structure-guided Transformers | CVPR 2025 | [Paper](https://arxiv.org/pdf/2412.11596) <br> [Code](https://github.com/DaoyiG/MeshArt) |
| <img src="assets/img/PrimitiveAnything.jpg" width="300"> | PrimitiveAnything: Human-Crafted 3D Primitive Assembly Generation with Auto-Regressive Transformer | SIGGRAPH 2025 | [Paper](https://arxiv.org/pdf/2505.04622) <br> [Code](https://github.com/PrimitiveAnything/PrimitiveAnything) |
| <img src="assets/img/OmniPart.jpg" width="300"> | OmniPart: Part-Aware 3D Generation with Semantic Decoupling and Structural Cohesion | arXiv 2025 | [Paper](https://arxiv.org/pdf/2507.06165) |
| <img src="assets/img/PartCrafter.jpg" width="300"> | PartCrafter: Structured 3D Mesh Generation via Compositional Latent Diffusion Transformers | arXiv 2025 | [Paper](https://arxiv.org/pdf/2506.05573) |
| <img src="assets/img/HoloPart.jpg" width="300"> | HoloPart: Generative 3D Part Amodal Segmentation | arXiv 2025 | [Paper](https://arxiv.org/pdf/2504.07943) <br> [Code](https://github.com/VAST-AI-Research/HoloPart) |
| <img src="assets/img/SPAFormer.jpg" width="300"> | SPAFormer: Sequential 3D Part Assembly with Transformers | 3DV 2025 | [Paper](https://arxiv.org/pdf/2403.05874) <br> [Code](https://github.com/xuboshen/SPAFormer) |
| <img src="assets/img/PASTA.jpg" width="300"> | PASTA: Controllable Part-Aware Shape Generation with Autoregressive Transformers | arXiv 2024 | [Paper](https://arxiv.org/pdf/2407.13677) |
| <img src="assets/img/PartGen.jpg" width="300"> | PartGen: Part-level 3D Generation and Reconstruction with Multi-View Diffusion Models | arXiv 2024 | [Paper](https://arxiv.org/pdf/2412.18608) <br> [Project](https://silent-chen.github.io/PartGen/) |
| <img src="assets/img/Part123.jpg" width="300"> | Part123: Part-aware 3D Reconstruction from a Single-view Image | SIGGRAPH 2024 | [Paper](https://arxiv.org/pdf/2405.16888) <br> [Project](https://liuar0512.github.io/part123_official_page/) |
| <img src="assets/img/DAE-NET.jpg" width="300"> | DAE-Net: Deforming Auto-Encoder for fine-grained shape co-segmentation | SIGGRAPH 2024 | [Paper](https://arxiv.org/pdf/2311.13125) <br> [Code](https://github.com/czq142857/DAE-Net) |
| <img src="assets/img/StructureNet.jpg" width="300"> | StructureNet: Hierarchical Graph Networks for 3D Shape Generation | SIGGRAPH Asia 2019 | [Paper](https://arxiv.org/pdf/1908.00575) <br> [Code](https://github.com/daerduoCarey/structurenet) |
| <img src="assets/img/PartNet.jpg" width="300"> | PartNet: A Large-scale Benchmark for Fine-grained and Hierarchical Part-level 3D Object Understanding | CVPR 2019 | [Paper](https://arxiv.org/pdf/1812.02713) [Dataset](https://partnet.cs.stanford.edu/) |
| <img src="assets/img/GenerativePArt.jpg" width="300"> | Generative 3D Part Assembly via Dynamic Graph Learning | NeurIPS 2020 | [Paper](https://arxiv.org/pdf/2006.07793) <br> [Code](https://github.com/hyperplane-lab/Generative-3D-Part-Assembly) |
| <img src="assets/img/ComplementMe.jpg" width="300"> | ComplementMe: Weakly-Supervised Component Suggestions for 3D Modeling | SIGGRAPH Asia 2017 | [Paper](https://arxiv.org/pdf/1708.01841) |
| <img src="assets/img/BSP-Net.jpg" width="300"> | BSP-Net: Generating Compact Meshes via Binary Space Partitioning | CVPR 2020 | [Paper](https://arxiv.org/pdf/1911.06971) <br> [Code](https://github.com/czq142857/BSP-NET-pytorch) |
| <img src="assets/img/GRASS.jpg" width="300"> | GRASS: Generative Recursive Autoencoders for Shape Structures | SIGGRAPH 2017 | [Paper](https://arxiv.org/pdf/1705.02090) |
| <img src="assets/img/PAGNet.jpg" width="300"> | Learning Part Generation and Assembly for Structure-Aware Shape Synthesis | AAAI 2020 | [Paper](https://arxiv.org/pdf/1906.06693) |
| <img src="assets/img/PartAssembly.jpg" width="300"> | Learning 3D Part Assembly from a Single Image | ECCV 2020 | [Paper](https://arxiv.org/pdf/2003.09754) |
| <img src="assets/img/CompoNet.jpg" width="300"> | CompoNet: Learning to Generate the Unseen by Part Synthesis and Composition | ICCV 2019 | [Paper](https://arxiv.org/pdf/1811.07441) |
| <img src="assets/img/ShapeAssembly.jpg" width="300"> | ShapeAssembly: Learning to Generate Programs for 3D Shape Structure Synthesis | SIGGRAPH Asia 2020 | [Paper](https://arxiv.org/pdf/2009.08026) <br> [Code](https://github.com/rkjones4/ShapeAssembly) |
| <img src="assets/img/PartVAE.jpg" width="300"> | Part-based 3D Object Reconstruction from a Single RGB Image | arXiv 2021 | [Paper](https://arxiv.org/pdf/2111.10180) |
| <img src="assets/img/PartSLIP.jpg" width="300"> | PartSLIP: Low-shot Part Segmentation for 3D Point Clouds via Pretrained Image-Language Models | CVPR 2023 | [Paper](https://arxiv.org/pdf/2212.01558) <br> [Code](https://github.com/colin97/PartSLIP) |
| <img src="assets/img/ProGRIP.jpg" width="300"> | Unsupervised Learning of Shape Programs with Repeatable Implicit Parts | NeurIPS 2022 | [Paper](https://papers.nips.cc/paper_files/paper/2022/hash/f6adf61977467560f79b95485d1f3a79-Abstract-Conference.html) <br> [Project](https://progrip-project.github.io/) |
| <img src="assets/img/SPAGHETTI.jpg" width="300"> | SPAGHETTI: Editing Implicit Shapes Through Part Aware Generation | ACM TOG 2022 | [Paper](https://arxiv.org/pdf/2201.13168) <br> [Code](https://github.com/amirhertz/spaghetti) <br> [Project](https://amirhertz.github.io/spaghetti/) |
| <img src="assets/img/BAE-NET.jpg" width="300"> | BAE-NET: Branched Autoencoder for Shape Co-Segmentation | ICCV 2019 | [Paper](https://openaccess.thecvf.com/content_ICCV_2019/papers/Chen_BAE-NET_Branched_Autoencoder_for_Shape_Co-Segmentation_ICCV_2019_paper.pdf) <br> [Code](https://github.com/czq142857/BAE-NET) |


## Others (Not yet classified)
|                                   Preview                                  | Title                                                                                                | Publication |                   Links                   |
| :------------------------------------------------------------------------: | :--------------------------------------------------------------------------------------------------- | :---------: | :---------------------------------------: |
| <img src="assets/img/GenerativeHumanGeometryDistribution.jpg" width="300"> | Generative Human Geometry Distribution                                                               |  Arxiv 2025 | [Paper](https://arxiv.org/pdf/2503.01448) |
|        <img src="assets/img/GeometryDistributions.jpg" width="300">        | Geometry Distributions                                                                               |  ICCV 2025  | [Paper](https://arxiv.org/pdf/2411.16076) |
| <img src="assets/img/functional_diffusion.jpg" width="300"> | Functional Diffusion | CVPR 2024 | [Paper](https://arxiv.org/abs/2311.15435) <br> [Code](https://github.com/1zb/functional-diffusion) <br> [Project](https://1zb.github.io/functional-diffusion/) |
|              <img src="assets/img/3DTopiaXL.jpg" width="300">              | 3DTopia-XL: Scaling High-quality 3D Asset Generation via Primitive Diffusion                         |  Arxiv 2024 | [Paper](https://arxiv.org/pdf/2409.12957) |
|        <img src="assets/img/GeometryImageDiffusion.jpg" width="300">       | Geometry Image Diffusion: Fast and Data-Efficient Text-to-3D with Image-Based Surface Representation |  Arxiv 2024 | [Paper](https://arxiv.org/pdf/2409.03718) |
|      <img src="assets/img/AnObjectIsWorth64x64Pixels.jpg" width="300">     | An Object is Worth 64√ó64 Pixels: Generating 3D Object via Image Diffusion                            |  Arxiv 2024 | [Paper](https://arxiv.org/pdf/2408.03178) |
|                 <img src="assets/img/XRay.jpg" width="300">                | X-Ray: A Sequential 3D Representation for Generation                                                 |  Arxiv 2024 | [Paper](https://arxiv.org/pdf/2404.14329) |
| <img src="assets/img/MeshCNN.jpg" width="300"> | MeshCNN: A Network with an Edge | SIGGRAPH 2019 | [Paper](https://arxiv.org/pdf/1809.05910) <br> [Code](https://github.com/ranahanocka/MeshCNN) |
| <img src="assets/img/NeuralMarchingCubes.jpg" width="300"> | Neural Marching Cubes | SIGGRAPH Asia 2021 | [Paper](https://arxiv.org/pdf/2106.11272)  <br> [Code](https://github.com/czq142857/NMC) |
| <img src="assets/img/APAP.jpg" width="300"> | As-Plausible-As-Possible: Plausibility-Aware Mesh Deformation Using 2D Diffusion Priors | CVPR 2024 | <br> [Project](https://visualai.kaist.ac.kr/) |
| <img src="assets/img/GET3D.jpg" width="300"> | GET3D: A Generative Model of High Quality 3D Textured Shapes Learned from Images | NeurIPS 2022 | [Paper](https://research.nvidia.com/labs/toronto-ai/GET3D/) <br> [Code](https://github.com/nv-tlabs/GET3D) |
| <img src="assets/img/SingleMeshDiffusion.jpg" width="300"> | Single Mesh Diffusion Models with Field Latents for Texture Generation | arXiv 2023 | [Paper](https://arxiv.org/pdf/2312.09250) |


---
